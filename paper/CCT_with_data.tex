% !TeX document-id = {8751af90-d4b1-40f9-88be-89e61cd71d0c}
% !TeX TXS-program:compile = txs:///pdflatex/[--shell-escape]
\documentclass[a4paper,11pt]{article}

%\usepackage[style=apa]{biblatex}
\usepackage[style=apa,sortcites=true,sorting=nyt,backend=biber]{biblatex}
\usepackage{amsmath,amsfonts,amssymb, bm}
\usepackage{graphicx,verbatimbox}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage[margin=1in]{geometry}
\usepackage{authblk}
\usepackage{nicefrac}
\usepackage{svg}
\usepackage{booktabs}
\usepackage{makecell} %\thead
\usepackage{array}
\newcolumntype{H}{>{\setbox0=\hbox\bgroup}c<{\egroup}@{}} % hidden column


%opening
\title{Augmenting Predictive Models in Forensic Psychiatry with Cultural Consensus Theory}
\author[1]{Don van den Bergh\thanks{%
Correspondence concerning this article should be addressed to Don van den Bergh, University of Amsterdam, Department of Psychological Methods, Postbus 15906, 1001 NK Amsterdam, The Netherlands. 
E-Mail should be sent to: donvdbergh@hotmail.com.
Don van den Bergh was supported by a Research Talent grant from the Netherlands Organization of Scientific Research (406-14-089 NWO).}}
\author[2]{Erwin Schuringa}
\author[1]{Eric-Jan Wagenmakers}
\affil[1]{Department of Psychological Methods, University of Amsterdam}
\affil[2]{Forensic Psychiatric Center Dr. S. van Mesdag}
\date{}

%\usepackage[dvipsnames]{xcolor}
\usepackage{xcolor}
\usepackage{todonotes}
\usepackage{float}

\definecolor{colorDon}{RGB}{205,250,255}
\definecolor{colorEJ} {RGB}{205,255,205}

\newcommand{\DB}[1]{\todo[inline, color=colorDon,caption={}]{DB: {#1}}}
\newcommand{\DBB}[1]{\todo[color=colorDon]{DB: {#1}}}
\newcommand{\EJ}[1]{\todo[inline, color=colorEJ]{EJ: {#1}}}

\newcommand{\githuburl}{\url{https://github.com/vandenman/CCT-Logistic}}

\graphicspath{{../figures/}{../graphicalmodels/}}

\addbibresource{references.bib}

\newcommand{\fig}{Fig.}

\setcounter{secnumdepth}{0}

\input{mycommands.tex}

\begin{document}

\maketitle
% TODO: Erwin om journal advies vragen?
% TODO: Ha Erwin, hier een ruwe draft, suggesties voor journals?
% TODO: dubbelcheck referenties (bv IFTE en niet ifte)

% \tableofcontents

\begin{abstract}
Forensic psychiatric hospitals regularly monitor the mental health and forensic risk factors of their patients.
As part of this monitoring, staff score patients on various items.
Common practice is to aggregate these scores across staff members.
However, this is suboptimal because it assumes that assessors are interchangeable and that patients are independent.
An improvement over averaging scores is the use of Cultural Consensus Theory (CCT), which imposes a hierarchical model across patients, staff members, and items.
While accounting for differences between patients and staff members, Cultural Consensus Theory estimates a ``true'' score for each patient on each item based on the consensus among staff members.
Here we apply a model based on Cultural Consensus Theory to data from a Dutch maximum security forensic psychiatric center and use the inferences to predict violent behavior in patients.
We compare the predictive value with several alternatives, such as random forest and boosted regression trees.
The paper concludes with a discussion of practical limitations and directions for how future monitoring of patients could be adapted to maximize the added value of a CCT-based approach.
\end{abstract}

% \section{Introduction} % Yes, this will be deleted before submission

The mental health and forensic risk factors of patients in forensic psychiatric hospitals is regularly monitored with methods such as Routine Outcome Monitoring \parencite{deBeurs2011ROM}.
A staff member (e.g., a clinician or psychiatrist), henceforth a \emph{rater}, scores a patient on variety of criteria, such as problematic behavior (e.g., hostility) or protective behavior (e.g., coping skills).
These scores are used to track the mental state of patients over time, to measure the effectiveness of treatment, and as a risk indicator for violent outbursts by patients.
% Using these scores raters can monitor the mental state of a patient over time, answer questions about the effectiveness of a treatment, or warn staff members about which patients are at risk for turning violent.

Typically, multiple raters score each patient on different items.
Standard practice is to average the scores across raters and use the averages to inform decisions.
However, this is suboptimal for multiple reasons. %\parencite{vandenBergh2020cultural}.
For example, taking the average implies that raters are interchangeable and patients are independent, rather than taking into account raters' bias or patients' offense.
% For example, this implies raters are exchangeable and patients are independent, rather than accounting for raters' biases or patients' criminal offense.

% In a typical data set there are for each patient multiple scores available on different items, given by different raters.
% Standard practice is to average the scores across raters and use those to inform decisions.
% This practice is suboptimal, as it treats raters as exchangeable and analyzes patients independently.

An improvement over averaging the scores is to use Cultural Consensus Theory \parencite[CCT;][]{romney1986culture, batchelder1988test, batchelder2012cultural} to construct an appropriate model for the scores that accounts for the hierarchical structure among patients, raters, and items.
In previous work, we developed such a model based on the Latent Truth Rater model \parencite[LTM; ][]{Anders2015cultural}, and demonstrated that, in theory, this model predicted better than the average and several machine learning alternatives.
However, due to the lack of an empirical dataset, we could not demonstrate whether the theoretical claims hold up in practice.

% In previous work, we used Cultural Consensus Theory \parencite[CCT;][]{romney1986culture, batchelder1988test, batchelder2012cultural} to develop an appropriate model to analyze such data that accounts for the hierarchical structure among patients, raters, and items \parencite{vandenBergh2020cultural}.

Here, we apply the CCT-based model to data of a Dutch maximum-security forensic psychiatric center and use its inferences to predict whether or not a patient becomes violent.
First, we briefly introduce the LTM model used and discuss two changes made compared to \textcite{vandenBergh2020cultural}.
Afterward, we use the LTM to augment a logistic regression.
We use the augmented model to predict violent outbursts in patients and compare the predictive performance to that of frequently used machine learning models.
We find that our LTM approach outperforms all other methods, albeit by a small margin.
Next, we interpret the fitted model, which shows that the prior history of violence is most predictive.
Finally, we discuss some practical limitations of the data set at hand and how future monitoring of patients could be adjusted to maximize the added benefit of our CCT-based approach.


\section{Mesdag Data}
% \DB{%
% Erwin, het zou fijn zijn als jij naar deze sectie kan kijken! Daarnaast had ik nog een paar vragen.
% \begin{enumerate}
%     \item De scores zijn op een schaal van 0-17 (met -99 als missing). Andere artikelen beschrijven echter een 17 puntsschaal. Stelt de score 0 iets speciaals voor?
%     \item Is de periode waarin de data zijn gemeten van april 2010 t/m juli 2016? (Een gokje gebaseerd op Schuringa et al. 2016)
%     \item Kloppen de Engelse vertalingen van de diagnoses en delicten?
%     \item Waarvoor staat As 1 overig?
%     \item Wat is (ongeveer) de minimum leeftijd van de patienten? 0 is namelijk een beetje raar in Tabel 1.
% \end{enumerate}
% }
% \subsection{Method of collection}
The data were collected in the Dutch maximum-security Forensic Psychiatric Center Dr. S. van Mesdag between October 2016 and February 2019.
The individual records were retrospectively merged into a single data set. 
In total, the data set contains information about 103 patients given by 188 raters on 23 items from 2 measurement occasions (18354 observations in total).
In addition to the scores on the IFTE items, the data set contains several background variables about the patients.
These are age (21-30, 31-40, 41-50, or 55+)\footnote{Ideally age is treated as a continuous variable. However, for privacy reasons, the data were made unidentifiable, for example by categorizing age.}, treatment duration (0-2 years, 2-4 years, 4-6 years, or 6+ years), diagnosis (schizophrenia and other psychotic disorders, autism spectrum disorder, Axis 1\footnote{Axis 1 is a combination of multiple disorders, such as substance related disorders (addiction, dependence, abuse), developmental disorders (ADHD, ADD),  mood disorders (depression, bipolar mood disorder), cognitive disorders (delirium, dementia, amnesia) sexual disorders (paraphilia, pedophilia) \parencite{segal2010diagnostic}. Note that DSM 4 categories are used as at the time of measurement not all DSM 4 diagnoses had been converted to DSM 5 diagnoses.}, personality disorder B, other personality disorders), offense (murder, arson, manslaughter, sex offense, aggravated assault, violent property crime, and moderately violent crime or a property crime), and history of violence (violent behavior 6 months before measurement 1, violent behavior 6 months before measurement 2, and violent behavior 6 months after measurement 2). When patients have multiple convictions, offense indicates the most serious conviction. A distinction between personality disorder B (composed of borderline, antisocial, and narcissistic personality disorder) and other personality disorders is made because patients with personality disorder B exhibited more violent behavior.

\subsection{IFTE}
The data were collected using a Routine Outcome Monitoring instrument called the Instrument for Forensic Treatment Evaluation (IFTE).
The IFTE consists of 22 items, of which 14 items are criminogenic need indicators of the Dutch risk assessment instrument HKT-R \parencite{spreen2013handleiding}, five items were designed in consultation with psychologists and psychiatrists, and three items are based on the Atascadero Skills Profile \parencite{vess2001development}.
The 22 items can be grouped into three factors, Protective behaviors, Problematic behaviors, and Resocialization Skills.
The individual items are shown in \autoref{tb:IFTE_items}.
All items are scored on a 17 point scale.
Before the IFTE is scored, the rater provides their clinical judgment to answer the question: ``Has the patient changed in this last period?'' on a 13 point scale.
This last item is treated as the 23\textsuperscript{rd} item of the IFTE here.
Each patient was scored with the IFTE on two separate occasions.
The 17 point scale contained 5 anchor points at 1, 5, 9, 13, and 17.
For example, for the item ``Does the patient show problem insight?'' these anchors would be `None', `Rarely', `Sometimes', `Often', and `Always'.
% Based on: 
% Before filling out the IFTE, the main clinician gives his/her clinical judgment whether he/she thinks the behavior of a patient has changed by answering the question: “Has the patient changed in this last period?” A 13-pointscale with four anchor points is used: 0 =“worsened,” 1 =“no change,” 2 =“a little improved” and 3 =“a lot improved.”

% \subsection{Covariates}
% In addition to the IFTE, several other background variables about the patients are available. %considered for predicting violent behavior.
% These are age (0-30, 31-40, 41-50, or 55+), treatment duration (0-2 years, 2-4 years, 4-6 years, or 6+ years), diagnosis (autism spectrum disorder, personality disorder, personality disorder B, schizophrenia or other psychotic disorders, and As 1 overig), offence (manslaughter, aggravated assault, murder, arson, violent property crime, moderately violent property crime, and Sexual offence), violent behavior before measurement 1, and violent behavior in between measurements 1 and 2.
% \DB{Check de juiste engelse vertalingen.}


\subsection{Descriptives}
Before introducing the models used and analyzing the data, we give a descriptive summary of the data.
\autoref{tb:backgroundinfo} shows the background characteristics of non-violent and violent patients.

\begin{table}[H]
    \caption{Characteristics of the non-violent and violent patients.}
    \label{tb:backgroundinfo}
    \centering
    \begin{tabular}{lr@{\hspace{\tabcolsep}}r@{\hspace{3\tabcolsep}}r@{\hspace{\tabcolsep}}r}
        \toprule
        % &  \thead[c]{Non-violent\\after T2}  & \thead[c]{Violent\\after T2} \\
        &  \multicolumn{2}{c}{\thead[c]{Non-violent\\after T2}} & \multicolumn{2}{c}{\thead[c]{Violent\\after T2}}\\
        \midrule
% \textbf{History of violence}	&&	  &\\
% \hspace{3mm} Non-violent before T1 	 & 68 (84\%) & 6 (25\%) \\
% \hspace{3mm} Violent before T1 	 & 13 (16\%) & 18 (75\%) \\
% \hspace{3mm} Non-violent before T2 	 & 70 (85\%) & 5 (21\%) \\
% \hspace{3mm} Violent before T2 	 & 12 (15\%) & 19 (79\%) \\
% \textbf{Age}		  &&\\
% \hspace{3mm} 21-30 	 & 5 (6\%) & 5 (21\%) \\
% \hspace{3mm} 31-40 	 & 41 (50\%) & 14 (58\%) \\
% \hspace{3mm} 41-50 	 & 26 (32\%) & 2 (8\%) \\
% \hspace{3mm} 51+ 	 & 10 (12\%) & 3 (12\%) \\
% \textbf{Treatment duration}		  &&\\
% \hspace{3mm} 0-2 years 	 & 32 (39\%) & 13 (54\%) \\
% \hspace{3mm} 2-4 years 	 & 20 (24\%) & 4 (17\%) \\
% \hspace{3mm} 4-6 years 	 & 15 (18\%) & 0 (0\%) \\
% \hspace{3mm} 6+ years 	 & 15 (18\%) & 7 (29\%) \\
% \textbf{Diagnosis}		  &&\\
% \hspace{3mm} As 1 Other 	 & 12 (15\%) & 1 (4\%) \\
% \hspace{3mm} Autism spectrum disorder 	 & 14 (17\%) & 2 (8\%) \\
% \hspace{3mm} Personality disorder cluster B 	 & 14 (17\%) & 9 (38\%) \\
% \hspace{3mm} Personality disorder other 	 & 9 (11\%) & 3 (12\%) \\
% \hspace{3mm} Schizophrenia and other psychotic disorders 	 & 32 (40\%) & 9 (38\%) \\
% \textbf{Offense}		  &&\\
% \hspace{3mm} Aggravated assault 	 & 14 (17\%) & 10 (42\%) \\
% \hspace{3mm} Arson 	 & 9 (11\%) & 2 (8\%) \\
% \hspace{3mm} Manslaughter 	 & 16 (20\%) & 2 (8\%) \\
% \hspace{3mm} Moderately violent property crime 	 & 9 (11\%) & 3 (12\%) \\
% \hspace{3mm} Murder 	 & 10 (12\%) & 1 (4\%) \\
% \hspace{3mm} Sex offense 	 & 17 (21\%) & 1 (4\%) \\
% \hspace{3mm} Violent property crime 	 & 6 (7\%) & 5 (21\%) \\
% \textbf{violent_before} &&\\ 

% \hspace{3mm}   Non-violent before T1   &        67 (84\%)   &   6 (25\%) \\
% \hspace{3mm}   Violent before T1   &        13 (16\%)   &   18 (75\%) \\
% % \textbf{violent_between} &&\\ 
% \hspace{3mm}   Non-violent before T2   &        68 (85\%)   &   5 (21\%) \\
% \hspace{3mm}   Violent before T2 &        12 (15\%)   &   19 (79\%) \\
% \textbf{Age} &&\\ 
% \hspace{3mm}   0-30   &        5 (6\%)   &   5 (21\%) \\
% \hspace{3mm}   31-40   &        40 (50\%)   &   14 (58\%) \\
% \hspace{3mm}   41-50   &        25 (31\%)   &   2 (8\%) \\
% \hspace{3mm}   51+   &        10 (12\%)   &   3 (12\%) \\
% \textbf{Treatment duration} &&\\ 
% \hspace{3mm}   0-2 years   &        32 (40\%)   &   13 (54\%) \\
% \hspace{3mm}   2-4 years   &        19 (24\%)   &   4 (17\%) \\
% \hspace{3mm}   4-6 years   &        14 (18\%)   &   0 (0\%) \\
% \hspace{3mm}   6+ years   &        15 (19\%)   &   7 (29\%) \\
% \textbf{Diagnosis} &&\\ 
% \hspace{3mm}   Schizophrenia and other psychotic disorders   &        31 (39\%)   &   9 (38\%) \\
% \hspace{3mm}   Autism spectrum disorder   &        14 (18\%)   &   2 (8\%) \\
% \hspace{3mm}   Axis 1   &        12 (15\%)   &   1 (4\%) \\
% \hspace{3mm}   Personality disorder cluster B   &        14 (18\%)   &   9 (38\%) \\
% \hspace{3mm}   Other personality disorders   &        9 (11\%)   &   3 (12\%) \\
% \textbf{Offense} &&\\ 
% \hspace{3mm}   Murder   &        10 (12\%)   &   1 (4\%) \\
% \hspace{3mm}   Arson   &        9 (11\%)   &   2 (8\%) \\
% \hspace{3mm}   Manslaughter   &        16 (20\%)   &   2 (8\%) \\
% \hspace{3mm}   Sex offense   &        17 (21\%)   &   1 (4\%) \\
% \hspace{3mm}   Aggravated assault   &        14 (18\%)   &   10 (42\%) \\
% \hspace{3mm}   Violent property crime   &        6 (8\%)   &   5 (21\%) \\
% \hspace{3mm}   Moderate violence / property crime   &        8 (10\%)   &   3 (12\%) \\

% \textbf{violent_before} &&&\\ 
\textbf{History of violence} &&&\\ 
\hspace{3mm}   Non-violent before T1   &        67 & (84\%)   &   6 & (25\%) \\
\hspace{3mm}   Violent before T1   &        13 & (16\%)   &   18 & (75\%) \\
\hspace{3mm}   Non-violent before T1   &        68 & (85\%)   &   5 & (21\%) \\
\hspace{3mm}   Violent before T1   &        12 & (15\%)   &   19 & (79\%) \\
\textbf{Age} &&&\\ 
\hspace{3mm}   21-30   &        5 & (6\%)   &   5 & (21\%) \\
\hspace{3mm}   31-40   &        40 & (50\%)   &   14 & (58\%) \\
\hspace{3mm}   41-50   &        25 & (31\%)   &   2 & (8\%) \\
\hspace{3mm}   51+   &        10 & (12\%)   &   3 & (12\%) \\
\textbf{Treatment duration} &&&\\ 
\hspace{3mm}   0-2 years   &        32 & (40\%)   &   13 & (54\%) \\
\hspace{3mm}   2-4 years   &        19 & (24\%)   &   4 & (17\%) \\
\hspace{3mm}   4-6 years   &        14 & (18\%)   &   0 & (0\%) \\
\hspace{3mm}   6+ years   &        15 & (19\%)   &   7 & (29\%) \\
\textbf{Diagnosis} &&&\\ 
\hspace{3mm}   Schizophrenia and other psychotic disorders   &        31 & (39\%)   &   9 & (38\%) \\
\hspace{3mm}   Autism spectrum disorder   &        14 & (18\%)   &   2 & (8\%) \\
\hspace{3mm}   Axis 1   &        12 & (15\%)   &   1 & (4\%) \\
\hspace{3mm}   Personality disorder cluster B   &        14 & (18\%)   &   9 & (38\%) \\
\hspace{3mm}   Other personality disorders   &        9 & (11\%)   &   3 & (12\%) \\
\textbf{Offense} &&&\\ 
\hspace{3mm}   Murder   &        10 & (12\%)   &   1 & (4\%) \\
\hspace{3mm}   Arson   &        9 & (11\%)   &   2 & (8\%) \\
\hspace{3mm}   Manslaughter   &        16 & (20\%)   &   2 & (8\%) \\
\hspace{3mm}   Sex offense   &        17 & (21\%)   &   1 & (4\%) \\
\hspace{3mm}   Aggravated assault   &        14 & (18\%)   &   10 & (42\%) \\
\hspace{3mm}   Violent property crime   &        6 & (8\%)   &   5 & (21\%) \\
\hspace{3mm}   Moderate violence / property crime   &        8 & (10\%)   &   3 & (12\%) \\
        \bottomrule
    \end{tabular}
\end{table}
The raw percentages suggest that patients with violent behavior after the second IFTE measurement were also more often violent before the first measurement and in between the two measurements.
For the other variables, there are no apparent differences between non-violent and violent patients.

Next, we examine the IFTE scores. 
\autoref{fig:descriptives_scores_hist} shows a histogram of the raw scores across all IFTE items, raters, and patients.
It is clear that the anchor points are given more often than the other scores ($\approx54\%$ of all scores are anchors points).
Furthermore, it appears that points in the middle of two anchor points are given more often than points adjacent of an anchor point (i.e., a 3 is scored more often over 2 or 4, a 7 is scored more often than 6 or 8, etc.).
\begin{figure}[!ht]
	\centering
	\includesvg[width=.8\textwidth]{descriptives_scores}
	\caption{Histogram of observed scores across all patients, items, raters, and time points. The first $x$-axis value, \emph{NA}, represents missing observations.}
	\label{fig:descriptives_scores_hist}
\end{figure}
Given the number of patients and raters it is evident that not all raters can have scored all patients.
\autoref{fig:descriptives_raters_by_patients} confirms this and shows that the rater by patient matrix is quite sparse.
\begin{figure}[!ht]
	\centering
	\includesvg[width=.8\textwidth]{descriptives_raters_by_patients}
	\caption{Heatmap of observed scores of rater ($x$-axis) against patients ($y$-axis).}
	\label{fig:descriptives_raters_by_patients}
\end{figure}



\section{Cultural Consensus Theory}

Cultural Consensus Theory, sometimes called ``test theory without an answer key'' \parencite{batchelder1988test}, is a method to discover the ``true answer'' for items from the consensus among the responses.
For example, suppose a patient is scored by multiple raters on hostile behavior.
Multiple scores are obtained that need to be aggregated to arrive at a single score for this patient.
The naive solution is to average these scores.
However, as shown in \autoref{fig:misFitMean} averaging may lead to severely biased estimates.
\begin{figure}[!ht]
	\centering
	\includesvg[width=\textwidth]{misfitMean}
	\caption{True item scores ($x$-axis) versus the sample mean across raters ($y$-axis) for three fictive patients. The left panel shows a scenario where the raters are heterogeneous and consequently the performance of the sample mean is poor. In the right panel the raters are homogeneous and the sample mean performs much better.}
	\label{fig:misFitMean}
\end{figure}

The average score disregards all additional information that is available.
It ignores the individual differences between raters, for example, this assumes that all psychiatrists score hostility in the same way, and it ignores group differences among raters, for example, there is no difference in scores by psychiatrists as opposed to clinicians, or other staff members.
In addition, the average ignores any additional information about the patient at hand, such as offense and diagnosis.

Cultural consensus theory provides a model-based framework for pooling information from multiple raters to form a consensus \parencite{anders2014cultural}.
There exist a variety of CCT models, each applicable to different types of data.
For example, the General Condorcet model \parencite{Batchelder1986statistical} applies to dichotomous data, the Continuous Response model \parencite{anders2014cultural} is suited for continuous data, and the Latent Truth Rater model \parencite{Anders2015cultural} is suited for ordinal data.
As the IFTE scores are ordinal, we use the Latent Truth Rater model to analyze the Mesdag data.

\subsection{The Latent Truth Rater Model}
The Latent Truth Rater Model (LTM) is a CCT model for ordinal data \parencite{Anders2015cultural}.
Previously, we extended the LTM to handle data from multiple patients \parencite{vandenBergh2020cultural} and \autoref{model:LTM_p} shows the LTM for multiple patients.
\begin{figure}[!ht]
	\begin{minipage}{0.55\textwidth}
		\centering
		\includegraphics[width=\textwidth, page=7]{graphicalmodels.pdf}
	\end{minipage}\hfill
	\begin{minipage}{0.45\textwidth}
		{\normalsize
			\begin{align*}
			\oneScore &\assignment
			\begin{cases}
			1		&\hspace{-.3cm} \text{if } \oneAppraisal \leq \Threshold_{\Irater 1} \\
			\Incat	&\hspace{-.3cm} \text{if } \Threshold_{\Irater, \Incat-1} < \oneAppraisal \leq \Threshold_{\Irater\Incat} \\
			\Tncat	&\hspace{-.3cm} \text{if } \oneAppraisal > \Threshold_{\Irater, \Tncat-1}
			\end{cases}\\
			\oneAppraisal &\sim \dlogis{\ItemTruth_{\Ipatient\Iitem}}{\nicefrac{\ItemDifficulty_\Iitem}{\RaterCompetence_\Irater}} \\
			\Threshold_{\Irater\Incat} &\sim \dnorm{0}{1}\\
			\ItemTruth_{\Ipatient\Iitem}        &\sim \dnorm{\mu_\ItemTruth}{\sigma_\ItemTruth^2}\\
			\ItemDifficulty_\Iitem   &\sim \dgammaMV{\mu_\ItemDifficulty}{\sigma_\ItemDifficulty^2} \\
			\RaterCompetence_\Irater &\sim \dgammaMV{\mu_{\RaterCompetence_\Irater}}{\sigma_{\RaterCompetence_\Irater}^2} \\
			\end{align*}
		}%
	\end{minipage}
	\caption{%
		Graphical model of the Latent Truth Rater Model for multiple patients.
		Note that the thresholds $\bm{\Threshold}_\Irater$ are constrained to be ordered, that is, for all raters we have $\Threshold_{\Irater 1} \leq \dots \leq \Threshold_{\Irater \Incat} \leq \dots \leq \Threshold_{\Irater,\Tncat-1}$.
	}
	\label{model:LTM_p}
\end{figure}

Here, $\oneScore$ is the observed score given to patient $\Ipatient$ on item $\Iitem$ by rater $\Irater$.
This score is assumed to be deterministically generated from a continuous latent appraisal $\Appraisal_{\Ipatient\Iitem\Irater}$ that is discretized to an ordinal scale by the thresholds $\Threshold_{\Irater\Incat}$.
In particular, we have that
\begin{align*}
\oneScore =
\left\{\begin{array}{ll}
1		& \text{if }  \Appraisal_{\Ipatient\Iitem\Irater} \leq \Threshold_{\Irater 1} \\[4pt]
\Incat	& \text{if }  \Threshold_{\Irater, \Incat - 1} < \Appraisal_{\Ipatient\Iitem\Irater} \leq \Threshold_{\Irater\Incat} \\[4pt]
\Tncat	& \text{if }  \Appraisal_{\Ipatient\Iitem\Irater} > \Threshold_{\Irater,\Tncat-1}
\end{array} \right.
\end{align*}
Since the appraisal score is latent, the deterministic function above implies the following probabilistic model over the observed scores:
\begin{align*}
P(\oneScore\mid \oneAppraisal,\bm{\Threshold}_{\Irater}) =
\left\{\begin{array}{ll}
1 - \cdf{\Appraisal_{\Ipatient\Iitem\Irater} - \Threshold_{\Irater 1}}         & \text{if } \oneScore = 1, \\[4pt]
\cdf{\oneAppraisal - \Threshold_{\Irater,\Incat-1}} -
\cdf{\oneAppraisal - \Threshold_{\Irater\Incat}}         & \text{if } 1 < \oneScore < \Tncat,\\[4pt]
\cdf{\oneAppraisal - \Threshold_{\Irater,\Tncat-1}}       & \text{if } \oneScore = \Tncat.
\end{array} \right.
\end{align*}
where $\cdf{}$ is the logistic cumulative distribution function.\footnote{%
	The choice of distribution function is arbitrary, in principle it is possible to use any continuous cumulative distribution function.
}

Next, we explain how the latent appraisals and thresholds come about.
The appraisals are drawn from a logistic distribution with location $\ItemTruth_{\Ipatient\Iitem}$, the true score for patient $\Ipatient$ on item $\Iitem$. The scale of the logistic distribution is the ratio of the item difficulty $\ItemDifficulty_\Iitem$ to the rater competence $\RaterCompetence_\Irater$.
A higher item difficulty means that the appraisals are more noisy, which leads to a more dispersed probability distribution over possible scores.
Conversely, a higher rater competence means that the appraisals are less noisy, which leads to a more concentrated distribution over the outcomes.
There are $\Tncat - 1$ ordered thresholds for each rater, which are assigned a standard normal prior for identification purposes.

There are two differences in the model specification above compared to our previous work \parencite{vandenBergh2020cultural}.
%We made two changes to the model, because when simulating data with similar characteristics as the Mesdag data, as
First, we previously modeled the thresholds using two rater-specific parameters.
However, in simulations, we noticed that these two parameters provide too little flexibility when the ordinal scale consists of 18 categories and has a multimodal distribution (see \autoref{fig:descriptives_scores_hist}), as in the Mesdag data.
Therefore we decided to model the thresholds individually.
This complicates interpreting the differences between the thresholds across raters, however, that is also not the goal of this paper.
Second, we previously allowed the item difficulty parameter to vary across patients, which captures that some items may be more difficult or easy to assess for some patients (e.g., some patients may cooperate more than others).
To estimate this patient-item interaction there must be a sufficient amount of raters that score each patient.
However, when simulating data with a ratio of raters to patients similar to that in the data at hand, we noticed that there are simply too few observations to reliably estimate the deviations in item difficulty across patients.
Therefore, we only vary item difficulty across items and not across patients.

Altogether, the LTM extracts a true score ($\ItemTruth_{\Ipatient\Irater}$) for each patient on every item while accounting for the hierarchical structure among patients, raters, and items.
We consider these true values to be the basis on which all follow-up analyses should take place.%, such as evaluating the mental state of a patient or usage as a risk indicator.

% \DB{We could also look at a patient specific ``cooperativeness'' parameter. Rather than doing $\ItemDifficulty_{\Ipatient\Iitem}$, which introduces $\Tpatient\times\Titem$ parameters, the logistic scale would become $\frac{\ItemDifficulty_\Iitem}{\RaterCompetence_\Irater \times\text{Cooperativeness}_\Ipatient}$. This introduces an additional $\Tpatient$ parameters.}


%$\Appraisal_{\Ipatient\Iitem\Irater} \leq \Threshold_{\Irater1}$ implies that $x_{\Ipatient\Iitem\Irater} = 1$, $\Threshold_{\Irater, \Incat - 1} < \Appraisal_{\Ipatient\Iitem\Irater} \leq \Threshold_{\Irater\Incat}$ implies that $x_{\Ipatient\Iitem\Irater} = \Incat$, and $\Appraisal_{\Ipatient\Iitem\Irater} > \Threshold_{\Irater\Tncat}$ implies that $x_{\Ipatient\Iitem\Irater} = \Tncat$.
%
%  that distributed with mean $\mu_{\Ipatient\Iitem\Irater}$ and standard deviation $\sigma_{\Iitem\Irater}$.
%
%
%Compared to our previous work, we made a few adjustments to make the model more suited for analyzing the data at hand.
%First, we removed
%
%
%Previously we modeled the thresholds using two rater specific parameters. However, during simulations we noticed that this is too restrictive when the ordinal scale consists of 18 categories, as in the data example at hand.


\subsection{Augmenting Logistic Regression with the LTM}
In a next step, we use logistic regression to predict violent behavior, where we use the estimated true scores ($\ItemTruth_{\Ipatient\Iitem}$) from the LTM as additional predictors.
We do so in a fully Bayesian approach, that is, we constructed a joint model for the violent behavior and the patient ratings.%
\footnote{%
An alternative is a two-step approach where in the first step the LTM is fit to the patient ratings.
In the second step, the estimates of the LTM (e.g., the posterior means) are used as predictors in a logistic regression model.
While this is computationally faster, it also ignores the uncertainty in the analysis of the patient ratings.
}
\autoref{model:Logistic_LTM} shows a graphical model of the logistic regression combined with the LTM.
The latent truth for each patient on each item is seen as a covariate in the logistic regression model.
\begin{figure}[!ht]
%	\begin{minipage}{0.5\textwidth}
		\centering
		\includegraphics[width=\textwidth, page=9]{graphicalmodels.pdf}
%	\end{minipage}\hfill
%	\begin{minipage}{0.5\textwidth}
%		{\normalsize
%			\begin{align*}
%			x_{\Ipatient\Iitem\Irater}      &\sim \dnorm{\mu_{\Ipatient\Iitem\Irater}}{\sigma^2_{\Ipatient\Iitem\Irater}} \\
%			\mu_{\Ipatient\Iitem\Irater}    &\assignment \RaterScale_\Irater \ItemTruth_{\Ipatient\Iitem} + \RaterShift_\Irater  \\
%			\sigma_{\Iitem\Irater} 			&\assignment \RaterCompetence_\Irater \ItemDifficulty_\Iitem\\
%			\ItemTruth_{\Ipatient\Iitem}	&\sim \dnorm{\mu_\ItemTruth}{\sigma^2_\ItemTruth}\\
%			\log \ItemDifficulty_\Iitem 	&\sim \dnorm{\mu_\ItemDifficulty}{\sigma^2_\ItemDifficulty}\\
%			\log \RaterScale_\Irater     	&\sim \dnorm{\mu_\RaterScale}{\sigma^2_\RaterScale}\\
%			\RaterShift_\Irater	   			&\sim \dnorm{\mu_\RaterShift}{\sigma^2_\RaterShift}\\
%			\log \RaterCompetence_\Irater	&\sim \dnorm{\mu_\RaterCompetence}{\sigma^2_\RaterCompetence}\\
%			\end{align*}
%		}%
%	\end{minipage}
	\caption{Graphical model of Logistic Regression Augmented with the Latent Truth Rater Model. The true scores }
	\label{model:Logistic_LTM}
\end{figure}
Here, $v_{\Ipatient}$ denotes the violent behavior of patient $\Ipatient$.
The regression coefficients of the true scores are denoted $\CovariateBeta_{\Iitem}$.
In addition to the true scores, we regress the background variables $\Covariate_{\Ipatient\Icovariate}$ with associates coefficients $\CovariateBeta_{\Icovariate}$ onto violent behavior.

The index $\Itime$ indicates the measurement occasion (1 or 2).
Rather than fitting the LTM completely anew for each time point, we assume that all rater parameters ($\ItemDifficulty_\Irater$ and $\bm{\Threshold}_{\Irater}$) and item parameters ($\ItemDifficulty_\Iitem$) constant but allowed the patient parameters to differ.

\subsection{Implementation}
We estimated the parameters of the LTM and the combined LTM-Logistic regression model using a Bayesian approach.
To explore the posterior distributions of the model parameters we used Stan \parencite{CarpenterEtAl2017Stan}.
Rather than Markov chain Monte Carlo (MCMC) we used variational inference, which was computationally faster while providing similar results in terms of parameter retrieval and model predictions \parencite{kucukelbir2017automatic}.
All analyses were done using R \parencite{R} and Stan models were run using the R package \code{cmdstanr} \parencite{cmdstanr}.
The code for the analyses is available in the online appendix at \githuburl{}.
Although the data cannot be shared due to privacy concerns, the repository contains simulated data that can be used to run the code.

The machine learning methods and the logistic regression models that will be introduced in the next section cannot handle missing values in the predictors.
Therefore, we imputed the missing values using the R package mice \parencite{miceRpackage}.
In the Bayesian analyses we marginalized out the missing values.

% \iffalse
% \subsection{Simulation Study}

% Before analyzing the data with the LTM, it is typically a good idea to run a simulation study to

% \subsubsection{Do we actually want to report this?}

% \subsubsection{Fit of the LTM}
% \fi

\section{Predictive Performance}

Here we compare the predictive performance of the logistic regression model that is augmented with the LTM (LR-LTM) to several reasonable alternatives and three baseline models.
The first baseline model is an intercept-only logistic regression (LR-Intercept). 
Comparing the predictive performance of a model with the LR-Intercept constitutes a coherence check that a model outperforms the baseline prevalence of violence.
The second baseline model we use is a logistic regression model with all covariates but not the IFTE items (LR-No IFTE).
As a third baseline model, we use a logistic regression model with only prior violence as predictors (LR-Violence).
% TODO: wat is de toegevoegde waarde van model 3 bovenop model 2?
As more plausible competing models, we consider logistic regression (LR), random forest, and boosted regression trees (GBM) which are trained with history of violence, patient covariates, and IFTE scores.
These three competing models have in common that they are designed for purely rectangular data.
That is, each row of the data set contains one outcome (violent or nonviolent behavior) and a number of predictors.
However, the raw data of the IFTE contains repeated observations, since patients were rated multiple times by different raters.
To accommodate this we (naively) average across different raters to obtain a single score for each item and time point.

Altogether, by comparing these seven models we aim to answer the following three questions: (1) Can predictive models outperform the base prevalence of violent behavior? (2) Do models with the IFTE scores perform better than the baseline models without? (3) Does the LR-LTM perform better than the models that naively average across raters?

To examine predictive performance we used 10-fold stratified cross-validation.
Each fold consisted of 8 nonviolent observations and 2 or 3 violent observations.
% For every fold, the data were split into a training set (80\%, $N = 84$) and a test set (20\%, $N = 20$).
% The models were fit on the training set and made predictions for the test set.
We quantified model performance with prediction accuracy and the Brier score \parencite{brier1950verification}.
Prediction accuracy is defined as the fraction of correct predictions.
We converted model probabilities for violent or non-violent behavior into binary predictions by comparing them with 0.5.
In other words, if a model prediction for observation $i$, $\hat{y}_i\in [0, 1]$, is larger than 0.5 then the predicted label is violent, otherwise, it is non-violent.
The Brier score is defined as $N^{-1}\sum_{i=1}^N\left(\hat{y}_i-y_{i}\right)^2$, i.e., the mean squared error between the observed labels, $y\in\{0,1\}$ and the model predictions.

\autoref{tb:predictions} shows the prediction accuracy and the Brier score averaged over the 10-folds.
The LR-LTM has the best classification of violence and the lowest Brier score, and the LR-Violence performs second best.
The difference in classification performance is $0.884 - 0.866 = 0.018$, which for a data set of 104 patients implies that the LR-LTM makes more accurate predictions than the LR-Violence for about 2 patients.
Possibly striking is the poor performance of the LR.
The standard logistic regression model clearly suffers from overfitting, as indicated by the high training performance but poor test performance. This result makes sense as the standard logistic regression model does not do anything special to combat overfitting, unlike the machine learning alternatives or Bayesian logistic regression used by the LR-LTM.


\begin{table}[!ht]
    \caption{Predictive performance of violent behavior. The values are the average of 10 cross-validations; the standard deviation is shown in parentheses.}
    \label{tb:predictions}
    \centering
    \begin{tabular}{lrrrr}
        \toprule
        & \multicolumn{2}{c}{Classification} & \multicolumn{2}{c}{Brier score}\\
        \cmidrule(lr){2-3}  \cmidrule(lr){4-5}
        Method & \multicolumn{1}{c}{Train} & \multicolumn{1}{c}{Test} & \multicolumn{1}{c}{Train} & \multicolumn{1}{c}{Test} \\
        \midrule \\
        % analyses without missings
        % LR-LTM & 0.980 (0.017) & 0.894 (0.074) & 0.043 (0.005) & 0.093 (0.034) \\
        % LR-Violence & 0.865 (0.007) & 0.866 (0.063) & 0.100 (0.003) & 0.107 (0.030) \\
        % LR-No IFTE & 0.948 (0.034) & 0.837 (0.105) & 0.032 (0.020) & 0.142 (0.109) \\
        % Random forest & 1.000 (0.000) & 0.835 (0.084) & 0.032 (0.002) & 0.114 (0.033) \\
        % GBM & 0.867 (0.009) & 0.828 (0.073) & 0.095 (0.002) & 0.126 (0.020) \\
        % LR & 1.000 (0.000) & 0.735 (0.144) & 0.000 (0.000) & 0.257 (0.147) \\
        % LR-Intercept & 0.769 (0.004) & 0.771 (0.038) & 0.177 (0.002) & 0.177 (0.020) \\
        % analyses with missings
        LR-LTM & 0.980 (0.008) & 0.884 (0.078) & 0.047 (0.006) & 0.095 (0.028) \\ 
        LR-Violence & 0.865 (0.007) & 0.866 (0.063) & 0.100 (0.003) & 0.107 (0.030) \\ 
        LR-No IFTE & 0.948 (0.034) & 0.837 (0.105) & 0.032 (0.020) & 0.142 (0.109) \\ 
        Random forest & 0.996 (0.006) & 0.835 (0.081) & 0.033 (0.002) & 0.114 (0.040) \\ 
        GBM & 0.880 (0.011) & 0.836 (0.066) & 0.093 (0.003) & 0.125 (0.023) \\ 
        LR & 1.000 (0.000) & 0.727 (0.182) & 0.000 (0.000) & 0.258 (0.173) \\ 
        LR-Intercept & 0.769 (0.004) & 0.771 (0.038) & 0.177 (0.002) & 0.177 (0.020) \\ 
        \bottomrule
    \end{tabular}
\end{table}

\autoref{fig:roc_curves} show the Receiver Operating Characteristic (ROC) curve and area under the curve (AUC) averaged across cross-validation runs for all methods except the LR-Intercept.\footnote{The ROC for the intercept-only model is by definition the identity function with an area under the curve of 0.5.}
For each cross-validation run, we computed the true positive rate and false-positive rate with the same set of thresholds run and afterward we averaged these.
The AUC was obtained by averaging the AUCs of each individual cross-validation, rather than computing the AUC for the averaged ROC curve.
In line with the previous results, the LR-LTM performs best and the LR-Violence method performs second best.

\begin{figure}[!ht]
    \centering
    \includesvg[width=.8\textwidth]{roc_curve_cv}
    \caption{ROC curves for the considered methods. The legend shows the area under the curve in parentheses.}
    \label{fig:roc_curves}
\end{figure}

To summarize, it is evident that all models, except for logistic regression, outperform the intercept-only baseline model.
Furthermore, the results show that the LTM augmented logistic regression model performs best, albeit by a small margin.
The logistic regression model with only violence (LR-Violence) outperformed the two machine learning alternatives that naively averaged the scores from the IFTE (GBM and Random forest).
This indicates that the IFTE has added value for prediction, but only if it is analyzed properly.

\section{Interpretation of the LTM}
Now that we have shown that the LTM had adequate predictive performance, we interpret the model parameters.
\autoref{fig:parameters} shows the posterior means and 95\% credible intervals for the LTM fitted to the complete data.
Prior history of violence has the largest coefficients, whereas the other coefficients all appear close to zero.
\begin{figure}[!ht]
    \centering
    \includesvg[width=\textwidth]{posterior_mean_95CRI2}
    \caption{Posterior means and 95\% credible intervals for the coefficients of the logistic regression model ($\CovariateBeta_{\Icovariate}$ and $\CovariateBeta_{\Iitem}$ in \autoref{model:Logistic_LTM}). The reference categories are treatment duration 0-2 years, diagnosis Axis 1, and offense arson. The abbreviations VPC, MPC, and AA stand for violent property crime, moderately violent property crime, and aggravated assault.}
    \label{fig:parameters}
\end{figure}
As \autoref{tb:backgroundinfo} already indicated, the history of violence has a large effect.
In contrast, the influence of the IFTE items is less clear as all coefficients appear to be close to zero.
However, unlike the other coefficients shown, the IFTE coefficients should be interpreted as random effects, as they are multiplied with the estimated latent truth $\ItemTruth_{\Ipatient\Iitem}$ which varies across patients.
This complicates interpreting the added value of the individual items of the LTM.
However, we can visualize the impact of the IFTE as a whole. %by examining $\sum_{\Irater}\ItemTrutherefore_{\Ipatient\Irater}\CovariateBeta_{\Irater}$.
\autoref{fig:IFTE_aggregate}, shows for each patient the posterior mean of the total impact of the IFTE for both measurements on the logit scale, which is given by $\sum_{t=1}^2\sum_{\Iitem=1}^{23}\ItemTruth_{\Ipatient\Iitem\Itime}\CovariateBeta_{\Iitem\Itime}$.
\begin{figure}[!ht]
    \centering
    \includesvg[width=.8\textwidth]{posterior_mean_IFTE_aggregate}
    \caption{Posterior mean of the effect of the total impact of the IFTE items for each patient. Shape and color indicate whether patients showed violent behavior or not.}
    \label{fig:IFTE_aggregate}
\end{figure}
For some patients, the posterior mean of the impact of the aggregated IFTE is as large as the effect of prior violence.
However, note that the uncertainty of these estimates is enormous, that is, the average credible interval ranges from -8 to 8.\footnote{The large uncertainty here is inevitable, as by adding the variance of the sum is usually close to the sum of the variance of the individual parameters.}
Nevertheless, \autoref{fig:IFTE_aggregate} shows that the IFTE matters for prediction, but also that the added value differs across patients.

\section{Discussion}
Here we applied a Cultural Consensus Theory model to scores of patients in a Forensic Psychiatric Center.
We used this CCT model to augment the predictive performance of a logistic regression model and showed that our CCT-infused logistic regression model outpredicted all other candidate models.
Interpreting the influence of individual items of the IFTE is not straightforward. 
However, the aggregated effect of the IFTE appeared substantial, but also varied across patients.
Nevertheless, the uncertainty in the parameter estimates is too large to warrant strong conclusions and interpretations, other than the logical finding that prior history of violent behavior is a strong predictor of future violence.

Here we devised a joint model for the IFTE scores and prediction of violent behavior.
An alternative approach is to first fit a CCT model to the IFTE scores and then in a second step use its estimates for prediction.
A disadvantage of this is that it ignores the uncertainty in the CCT estimates.
On the other hand, a pragmatic advantage is that it decreases the running time of the models.
Furthermore, a two-step approach also opens up the possibility to use machine learning methods for prediction.
While such an approach has shown merit before \parencite[see e.g.,][]{plonsky2017psychological}, it is probable that using a machine learning model would further complicate the interpretation of the model parameters and predictions which may have the unintended effect that in practice the recommendations are not adopted because the model cannot be fully understood.

\subsection{Suggestions for Future Data Collection}

The interpretation of the parameters of the LTM in this application is hindered by the use of unconstrained thresholds.
However, this modeling decision was mandated by the structure of the data, which, due to the large number of response categories, showed patterns that could not be described by a simpler function for the thresholds (e.g., a preference for anchor points).
These response patterns were somewhat unexpected, as earlier studies did not observe such patterns \parencite[e.g., see Figure 2 of ][]{schuringa2014inter}.
For future data collection, it would be worthwhile to explore options to normalize the distribution of response scores.
This could be done by through more clear instructions for the raters, or collapsing infrequently used response categories.
A normal That would facilitate modeling of the data and simultaneously reduce the likelihood of spurious patterns in the data.

The frequency of measurements is key to the usefulness of the IFTE scores.
\textcite{schuringa2019inpatient} previously found that the most recent measurement is most predictive, which indicates that the scores' predictive value likely decreases over time.
% It was previously found that the most recent measurement is most predictive \parencite{schuringa2019inpatient}, which indicates that the scores' predictive value likely decreases over time.
Rather than scoring patients every 6 months, as in the data at hand, it would make more sense to rate them every few weeks.
Although it may be practically difficult to score patients regularly, there are opportunities to use self-reports for this purpose \parencite{tuente2021mapping, bousardt2016predicting}.
A downside of self-reports is that they may introduce additional variance due to the lack of standardized scoring, or meaningless responses in case of non-cooperation.

\subsection{Limitations}
A limitation of our approach is that patients' violent behavior is not a discrete event as we modeled it, but rather a continuous process where the risk of violent behavior changes over time.
This limits the direct applicability of our approach in practice.
To accommodate time series data, the model could be extended, for example, by adding autoregressive components.

Furthermore, we did not account for the structure of the IFTE items.
Each item of the IFTE is designed to load on a particular factor, see \autoref{tb:IFTE_items}.
This structure could be added to the model introduced here as a confirmatory factor model.
This would imply that the true scores $\ItemTruth_{\Ipatient\Iitem}$ load on their common factors, and that the factor scores are used to predict violent behavior.
If the factor model fits well then it could make the model interpretation easier, as this can then be done on the level of the factor rather than the items.
However, it is unlikely that this would improve predictive performance.
On the other hand, if the factor model does not fit well then predictive performance would suffer.

\subsection{Conclusion}
In sum, we applied the LTM introduced by \textcite{Anders2015cultural} and adapted previously by us in \textcite{vandenBergh2020cultural} to data of patients in a Forensic Psychiatric Center.
We showed that including the IFTE items slightly improves predictive performance, but only if the scores from different raters are analyzed properly and not when the scores of different raters are averaged.
We discussed different approaches to make the data more informative and to further extend the models.

\printbibliography
\newpage

\appendix

\section{IFTE items}

\begin{table}[!ht]
    \centering
    \caption{%
 	Overview of the 22 IFTE Items, the factor on which they load, and the origin of the question. Adapted from Table~1 of \textcite{schuringa2014inter}.
 	}
 	\label{tb:IFTE_items}
 	\begin{tabular}{>{\small}llH}
%  	\begin{tabular}{>{\small}lll}
 	\toprule
    Item description                                                                                        &   Factor                  &   Origin                  \\
    \midrule
    Does the patient show problem insight?                                                                  &   Protective behaviors    &   HKT-R                   \\
    Does the patient cooperate with your treatment?                                                         &   Protective behaviors    &   HKT-R                   \\
    Does the patient admit and take responsibility for the crime(s)?                                        &   Protective behaviors    &   HKT-R                   \\
    Does the patient show adequate coping skills?                                                           &   Protective behaviors    &   HKT-R                   \\
    Does the patient have balanced daytime activities?                                                      &   Resocialization Skills  &   HKT-R                   \\
    Does the patient show sufficient labor skills?                                                          &   Resocialization Skills  &   HKT-R                   \\
    Does the patient show sufficient common social skills?                                                  &   Resocialization Skills  &   HKT-R                   \\
    Does the patient show sufficient skills to take care of oneself?                                        &   Resocialization Skills  &   HKT-R                   \\
    Does the patient show sufficient financial skills?                                                      &   Resocialization Skills  &   Proposed by clinicians  \\
    Does the patient show impulsive behavior?                                                               &   Problematic behavior    &   HKT-R                   \\
    Does the patient show antisocial behavior?                                                              &   Problematic behavior    &   HKT-R                   \\
    Does the patient show hostile behavior?                                                                 &   Problematic behavior    &   HKT-R                   \\
    Does the patient show sexual deviant behavior?                                                          &   Problematic behavior    &   Proposed by clinicians  \\
    Does the patient show manipulative behavior?                                                            &   Problematic behavior    &   Proposed by clinicians  \\
    \thead[l]{Does the patient comply with the rules\\ and conditions of the center and/or the treatment?}  &   Problematic behavior    &   HKT-R                   \\
    Does the patient have antisocial associates?                                                            &   Problematic behavior    &   HKT-R                   \\
    \thead[l]{Does the patient use his medication in a consistent and adequate manner?}                   &   Protective behaviors    &   Proposed by clinicians  \\
    Does the patient have psychotic symptoms?                                                               &   Problematic behavior    &   HKT-R                   \\
    Does the patient show skills to prevent drug and alcohol use?                                           &   Protective behaviors    &   ASP                     \\
    Does the patient use any drug or alcohol?                                                               &   Problematic behavior    &   HKT-R                   \\
    Does the patient show skills to prevent physical aggressive behavior?                                   &   Protective behaviors    &   ASP                     \\
    Does the patient show skills to prevent sexual deviant behavior?                                        &   Protective behaviors    &   ASP                     \\
    \bottomrule
 	\end{tabular}
\end{table}


%\section{EM Algorithm}
%
%Initial values are found using a few steps of an EM-algorithm that disregards the priors and hyperparameters.
%\begin{align*}
%	\RaterShift_\Irater &\sim \prod_{\Ipatient=1}^\Tpatient\prod_{\Iitem=1}^\Titem \dnorm{x_{pir} - \RaterScale_\Irater\ItemTruth_{\Ipatient\Iitem}}{\left(\ItemDifficulty_\Iitem\RaterCompetence_\Irater\right)^2} \\
%	\RaterScale_\Irater &\sim \prod_{\Ipatient=1}^\Tpatient\prod_{\Iitem=1}^\Titem
%	\dnorm{\frac{
%			\RaterShift_\Irater - x_{pir}
%		}{
%			\ItemTruth_{\Ipatient\Iitem}
%		}}{
%		\left(\frac{
%			\ItemDifficulty_\Iitem\RaterCompetence_\Irater
%		}{
%			\left|\ItemTruth_{\Ipatient\Iitem}\right|}\right)^2
%		} \\
%	\ItemTruth_{\Ipatient\Iitem} &\sim \prod_{\Irater=1}^\Trater
%	\dnorm{\frac{
%			x_{pir} - \RaterShift_\Irater
%		}{
%			\RaterScale_\Irater
%		}}{
%		\left(\frac{
%			\ItemDifficulty_\Iitem\RaterCompetence_\Irater
%		}{
%			\RaterScale_\Irater}\right)^2
%	} \\
%	\RaterCompetence_\Irater^2 &\sim \dinvgamma{\frac{\Tpatient\Titem}{2}-1}{
%		\sum_{\Iitem=1}^\Titem \frac{1}{2\ItemDifficulty_\Iitem^{2}}\sum_{\Ipatient=1}^\Tpatient
%		\left(x_{pir} - \RaterScale_\Irater\ItemTruth_{\Ipatient\Iitem} - \RaterShift_\Irater\right)^2
%	}\\
%	\ItemDifficulty_\Iitem^2 &\sim \dinvgamma{\frac{\Tpatient\Trater}{2}-1}{
%		\sum_{\Irater=1}^\Trater \frac{1}{2\RaterCompetence_\Irater^{2}}\sum_{\Ipatient=1}^\Tpatient
%		\left(x_{pir} - \RaterScale_\Irater\ItemTruth_{\Ipatient\Iitem} - \RaterShift_\Irater\right)^2
%	}
%\end{align*}

\end{document}
